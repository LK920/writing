# 멘토링 세션: 질문-답변 구조

## 1. 질문: 지수 님이 Redis의 적정 인스턴스 개수와 비중에 대해 왜 질문했을까?
**답변**:
- **질문 배경**: 발제에서 지수 님이 Redis의 적정 인스턴스 개수와 비중에 대해 질문했으며, 참석자 1이 의도를 묻자 참석자들이 명확히 모르는 상황.
- **인스턴스 개수**:
  - 분산 락 사용 시 홀수 개 인스턴스(3, 5, 최대 7개) 추천.
  - 인스턴스 증가 시 락 획득 부담 증가, 정밀 제어 필요 없으면 3개로 충분.
  - 4개 사용 시 스플릿 브레인 문제 크지 않으나, 가능성 인지 필요.
  - 굳이 홀수로 맞출 필요 없음, 문제 발생 시 대응 가능.
- **인스턴스 비중**:
  - 캐시는 장애 시 전면 장애로 이어져 중요도가 높음.
  - 초기에 캐시와 분산 락을 동일 인프라로 운영, 사용량 증가 시 분리.
  - 예: 3대4 비율로 캐시와 분산 락 인프라 구성.
  - 인프라 통합은 운영 공수와 비용 절감에 유리.
- **운영 전략**:
  - 매트릭으로 사용량 추이 확인 후 필요 시 인프라 분리.
  - 추가 인프라는 세팅 및 운영 비용(인프라 세팅, 모니터링 등) 고려.
  - 비즈니스 요구에 따라 인프라 구성 조정.

**키워드**: Redis, 분산 락, 홀수 인스턴스, 스플릿 브레인, 캐시, 인프라 운영, 비용 효율성  
**설명**: Redis 인스턴스 수는 분산 락 안정성과 성능에 영향. 홀수 개(3~5개) 권장, 캐시와 분산 락 초기에 통합 운영 후 필요 시 분리. 스플릿 브레인 문제는 심각하지 않으나 인지 필요.

---

## 2. 질문: 재시도 로직에서 Redis 사용 시 고려할 점은?
**답변**:
- **CAP 이론과 네트워크 장애**:
  - CAP 이론(일관성, 가용성, 파티션 허용성)에 따라 네트워크 장애는 필연적.
  - MSA 환경에서 네트워크 빈도 높아 재시도 로직 설계 중요.
- **재시도 문제**:
  - 과다 재시도는 서버 부하 유발.
  - 예: 서버 장애 시 10번 재시도는 회복 시간 부족, 서버 부담 가중.
- **민감한 서비스(포인트 지급) 전략**:
  - 타임아웃(3초)보다 처리 시간(3.5초) 길 경우, 클라이언트가 실패로 오인.
  - 해결:
    1. DB에 원장 기록.
    2. 포인트 지급 요청.
    3. DB 갱신(지급 완료).
    4. 미지급 내역 배치 처리.
  - 민감한 서비스는 배치로 재시도 관리, 단순 서비스는 리트라이 가능.
- **배치 주기**:
  - 비즈니스 요구사항(예: 30분 내 지급)에 맞춰 설정.
  - 포인트 지급은 5~15분 주기 적절.
  - 고객 민원 최소화를 위해 빠른 주기 선호.
- **비즈니스 연계**:
  - 비즈니스 이해 필수, 주기는 비즈니스 민원 패턴에 따라 조정.
  - 예: 포인트 지급 지연 시 고객 문의 대응(30분 내 처리 안내).

**키워드**: CAP 이론, 네트워크 장애, 재시도 로직, 포인트 지급, 원장, 배치 처리, 비즈니스 요구사항  
**설명**: 네트워크 장애로 인한 재시도는 서버 부하 유발. 민감한 서비스는 DB 원장과 배치 처리로 관리, 배치 주기는 비즈니스 요구(5~15분)에 맞춰 조정.

---

## 3. 질문: 실무에서 Redis를 자극적으로 사용한 사례는?
**답변**:
- **Redis 도입 필요성**:
  - 트래픽 높은 환경에서 필수.
  - 예: 토스 이벤트(공유하고 리워드 받기, 하루 6700만 접속).
    - 계산: 600만 접속 ÷ 24시간 ÷ 60분 ÷ 60초 = 초당 약 70건.
    - 피크 트래픽은 2~3배(210건), DB만으로 감당 어려움.
  - 부하 테스트로 DB 한계 확인 시 Redis 도입.
- **사례**:
  - **네이버 SMS 발송**: 해커의 반복 인증 요청으로 비용 증가.
    - Redis로 발송 주기 카운팅, DB 테이블 생성 없이 해결.
  - 다중 서버 간 데이터 동기화, 고 TPS(초당 4~5천) 처리에 Redis 적합.
- **Lua 스크립트**:
  - Redis는 싱글 스레드로 원자성 보장.
  - Get-set 연산은 원자성 미보장(중간에 다른 요청 개입 가능).
  - Lua 스크립트로 동시성 문제 해결, 예: 데이터 조회 후 조작 저장.
- **적용 시기**:
  - 트래픽 계산 및 부하 테스트로 필요성 판단.
  - DB TPS 한계 초과 시 Redis 필수.
  - 서비스별 TPS 제한으로 Redis 사용 필연적.

**키워드**: Redis, 트래픽, 부하 테스트, TPS, SMS 발송, Lua 스크립트, 동시성, 원자성  
**설명**: 높은 트래픽에서 Redis는 DB 부하 감소 및 데이터 동기화에 유용. SMS 발송 주기 관리, Lua 스크립트로 동시성 제어가 대표 사례.

---

## 4. 질문: Redis로 인한 성능 저하 사례는?
**답변**:
- **성능 저하 상황**:
  - Redis는 초당 10만 건 이상 처리 가능.
  - 예: 토스 고양이 게임, 자정 100만 명 동시 캐시 만료 요청.
    - 캐시 만료 시 백그라운드 스레드 처리, 과다 요청 시 부하 발생.
- **해결책**:
  - TTL을 고정값(예: 24시간) 대신 랜덤값으로 설정해 부하 분산.
  - 예: 자정에 모든 캐시 TTL 만료 시 Redis 부담 증가.
  - Redis 템플릿에서 TTL 설정 시 랜덤값 추가(예: 24시간 ± 랜덤 초).
- **비즈니스 고려**:
  - 트래픽 패턴 분석, 예: 100만 명 ÷ 1000초 = 초당 1000건 처리.
  - 사용자 1명일 경우 TTL 분산 불필요, 대규모 트래픽 시 필수.
  - 비즈니스 이해로 데이터 기반 TTL 조정.

**키워드**: Redis, 성능 저하, 캐시 만료, TTL, 랜덤값, 트래픽 분산  
**설명**: 대규모 트래픽에서 동시 캐시 만료는 Redis 부하 유발. TTL에 랜덤값 적용으로 부하 분산, 트래픽 패턴과 비즈니스 요구에 따라 조정.

---

## 5. 질문: Redis를 단독으로 사용하는지, 지원 기능으로 사용하는지?
**답변**:
- **스프링에서의 Redis**:
  - **Cacheable**: 단순 조회/삭제 지원, 스프링의 캐시 추상화(AOP 기반).
  - **Redis 템플릿**: 세밀한 제어(예: TTL 분산) 필요 시 사용.
  - 스프링 PSA(Portable Service Abstraction)로 기술 독립성 보장.
  - Cacheable은 Redis 외 로컬 캐시도 지원.
- **사용 패턴**:
  - Redis는 캐시 시장 99% 점유, Redis 템플릿은 사용성 편리.
  - 예: TTL 분산, 세부 제어 시 Redis 템플릿 필수.
- **낙관적 락 vs 분산 락**:
  - 낙관적 락: DB 테이블 수정 필요, DBA 요청 등 비효율적.
  - 분산 락: 동시성 문제 해결에 선호, 99% 사용.
  - 비관적 락: 데드락 우려로 사용 안 함, DB 라이트 사용 선호.
- **현실적 고려**:
  - 대기업은 DBA 일정으로 테이블 수정 어려움.
  - 분산 락으로 대부분 문제 해결, 간단한 경우 낙관적 락 유지 가능.

**키워드**: Redis 템플릿, Cacheable, PSA, 낙관적 락, 분산 락, 비관적 락, 동시성  
**설명**: Redis는 Cacheable로 기본 사용, 세밀 제어 시 Redis 템플릿 활용. PSA로 추상화 지원, 분산 락이 낙관적/비관적 락보다 선호됨.

---

## 6. 질문: 분산 락 통합 테스트는 어떻게 작성해야 하나?
**답변**:
- **스프링 슬라이스 테스트**:
  - 세부 계층 테스트 지원(예: JSON, JPA, 웹 MVC).
  - Redis 테스트: `@DataRedisTest`로 Redis 환경 구성.
- **통합 테스트**:
  - 서비스 단위로 주입받아 동일 기능 반복 호출로 검증.
  - 기존 동시성 테스트(스레드, 카운트다운 래치)로 분산 락 검증 가능.
  - 멀티 서버 테스트는 복잡, 기존 테스트 활용 권장.
- **고려사항**:
  - 분산 락 테스트는 동시성 검증 중심.
  - 실제 환경(서버 여러 대) 반영보다 서비스 단위 테스트로 충분.

**키워드**: 슬라이스 테스트, DataRedisTest, 통합 테스트, 동시성, 분산 �락  
**설명**: 스프링 슬라이스 테스트로 Redis 테스트 가능. 서비스 단위 통합 테스트로 동시성 검증, 복잡한 멀티 서버 테스트 대신 기존 테스트 활용.

---

## 7. 질문: 캐시 키 관리는 어느 정도 깊이로 해야 하나?
**답변**:
- **캐시 키 설계**:
  - 공통 캐시 서버 사용 시 프리픽스 필수(예: `[서버명]::[기능]::[디바이스 ID]::[날짜]`).
  - 예: 토스에서 서버별 캐시 구분, 쿼리 시 프리픽스로 전체 캐시 처리.
- **키 길이 문제**:
  - 캐시 키(예: 32자 문자열)가 값(예: 정수)보다 길어 비효율적.
  - 대용량 서비스(예: 5천만 사용자)에서 키 길이 단축 노력(압축, BI 축소).
- **검색어 캐시**:
  - 질의 패턴(날짜, 검색어)에 따라 캐시 키 다르게 설계.
  - 예: 동일 데이터라도 날짜 키, 검색어 키로 중복 저장.
  - 친구 목록 서비스: 사용자 번호, 날짜별 캐시 키로 중복 저장.
- **중복 저장**:
  - 중복 피하는 것이 이상적이나, 질의 패턴에 따라 불가피.
  - 설계상 필요 시 중복 허용, 비즈니스 요구 반영.

**키워드**: 캐시 키, 프리픽스, 키 길이, 중복 저장, 검색어 캐시  
**설명**: 캐시 키는 프리픽스로 서버 구분, 질의 패턴에 따라 설계. 대용량 서비스에서 키 길이 최적화, 중복 저장은 질의 요구에 따라 허용.

---

## 8. 질문: 비관적 락 사용 여부와 웨이트 타임, TTL 설정 방법은?
**답변**:
- **비관적 락**:
  - 사용 경험 없음, 데드락 우려로 선호하지 않음.
  - DB 장애 60~70% 관련, DB 라이트 사용 선호.
- **분산 락 구현**:
  - **스핀락**: 반복적 Redis 요청, 리트라이 유사, 부하 발생.
  - **Pub/Sub**: 락 해제 시 알림, 호출 횟수 적어 성능 우수.
  - 토스: 스핀락 기반, 클라이언트 버튼 비활성화로 부하 감소(예: 포인트 지급 연타 방지).
- **웨이트 타임/TTL**:
  - 웨이트 타임: 락 대기 시간, 서비스별로 상이.
  - TTL: 락 유지 시간, 일반적으로 0.5초 적절.
  - 0.5초 내 락 획득 실패 시 Redis 문제로 간주.
- **클라이언트-서버 협업**:
  - 클라이언트 버튼 비활성화로 중복 요청 방지.
  - 서버는 백업 역할, 동시성 제어 효율적.

**키워드**: 비관적 락, 분산 락, 스핀락, Pub/Sub, 웨이트 타임, TTL, 클라이언트-서버 협업  
**설명**: 비관적 락은 데드락 우려로 사용 안 함. 분산 락은 Pub/Sub이 성능 우수, 스핀락은 토스에서 사용. TTL은 0.5초 권장, 클라이언트 협업으로 부하 감소.

---

## 9. 질문: 통계성 데이터에 캐시를 사용하는 경우는?
**답변**:
- **통계성 데이터**:
  - 타임 시리즈 DB(예: 시계열 DB) 적합, 예: 광고 노출 수.
  - RDB는 고빈도 통계 데이터 처리 어려움.
- **도입 고려**:
  - 타임 시리즈 DB 도입은 운영 비용 및 전문성 문제.
  - RDB는 예상보다 잘 버팀, 토스에서는 통계용 DB 별도 구성.
- **운영 전략**:
  - 읽기 전용 배치/어드민 DB로 통계 처리(예: 1분 넘는 쿼리).
  - 별도 DB 구축은 비용 높음, 데이터 엔지니어 역할 중요.
  - 데이터 플랫폼 엔지니어가 통계 데이터 관리, 운영 공수 고려.
- **현실적 접근**:
  - 민감하지 않은 서비스는 RDB 활용.
  - 스타벅스 같은 분석용 DB도 비용 문제로 제한적 사용.

**키워드**: 통계성 데이터, 타임 시리즈 DB, RDB, 운영 비용, 데이터 엔지니어  
**설명**: 통계 데이터는 타임 시리즈 DB가 이상적이나 비용 문제로 RDB 활용. 읽기 전용 DB로 통계 처리, 데이터 엔지니어의 역할과 운영 공수 고려.

---

## 10. 질문: 캐시 삭제 전략은? 모든 데이터에 TTL을 적용해야 하나?
**답변**:
- **삭제 전략**:
  - **액티브 삭제**: 코드로 캐시 명시적 삭제.
  - **패시브 삭제**: TTL 설정으로 자동 삭제.
  - 둘 다 사용 권장, 빠른 삭제로 용량 확보, TTL로 누락 방지.
- **고려사항**:
  - 대량 캐시 삭제 시 Redis 부하 발생.
  - 예: 자정 100만 캐시 만료는 백그라운드 스레드 부담.
  - TTL 설정 필수, 랜덤값 추가로 부하 분산.
- **면접 대비**:
  - 데이터 삭제 정책 질문 빈번, 액티브/패시브 방식 이해 필요.

**키워드**: 캐시 삭제, 액티브 삭제, 패시브 삭제, TTL, 부하 분산  
**설명**: 캐시 삭제는 액티브(명시적)와 패시브(TTL) 방식 병행. 대량 삭제 시 부하 주의, TTL 설정과 랜덤값으로 안정성 확보.

---

## 11. 질문: 추가 질문 및 과제 관련 요청은?
**답변**:
- **추가 질문**:
  - 모든 질문 다룸, 추가 질문은 자유롭게 요청.
- **과제 제출**:
  - PR에 질문 및 리뷰 포인트 작성.
  - 질문 개수 제한 신경쓰지 않고 편하게 질문.
- **학습 권장**:
  - Redis 싱글 스레드, 액티브/패시브 삭제 방식 학습.
  - 구현 및 피드백 반영 시간 활용.
  - 트랜잭션 전파 속성(예: REQUIRES_NEW) 주의:
    - 예: API 요청 내 3개 트랜잭션 → DB 커넥션 16개 ÷ 3 = TPS 5 제한.
    - DB 커넥션 소중히 다뤄야, 무지성 REQUIRES_NEW 사용 지양.

**키워드**: 추가 질문, 과제 제출, Redis 학습, 싱글 스레드, 트랜잭션 전파, DB 커넥션  