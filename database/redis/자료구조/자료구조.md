---
title: "Redis 자료구조 완벽 가이드 - String부터 Stream까지"
tags:
  - Redis
  - 레디스
  - 자료구조
  - 데이터베이스
  - NoSQL
  - 캐시
  - 인메모리데이터베이스
  - String
  - List
  - Hash
  - Set
  - SortedSet
  - Bitmap
  - HyperLogLog
  - Geospatial
  - Stream
  - 키관리
---

# Redis 자료구조 완벽 가이드

Redis는 다양한 자료구조를 지원하는 인메모리 데이터베이스입니다. 이 글에서는 Redis의 모든 주요 자료구조와 키 관리 방법을 상세히 다룹니다.

## 목차

1. [String - 가장 기본적인 자료구조](#1-string---가장-기본적인-자료구조)
2. [List - 순서가 있는 데이터](#2-list---순서가-있는-데이터)
3. [Hash - 필드-값 쌍 저장](#3-hash---필드-값-쌍-저장)
4. [Set - 중복 없는 집합](#4-set---중복-없는-집합)
5. [Sorted Set - 정렬된 집합](#5-sorted-set---정렬된-집합)
6. [Bitmap - 비트 단위 연산](#6-bitmap---비트-단위-연산)
7. [HyperLogLog - 효율적인 카디널리티 추정](#7-hyperloglog---효율적인-카디널리티-추정)
8. [Geospatial - 위치 데이터 관리](#8-geospatial---위치-데이터-관리)
9. [Stream - 메시지 브로커](#9-stream---메시지-브로커)
10. [키 관리 - 효율적인 키 운영](#10-키-관리---효율적인-키-운영)

---

## 1. String - 가장 기본적인 자료구조

**가장 단순한 자료구조**로, Key-Value 1:1 매핑 구조입니다.
- **최대 저장 크기**: 512MB
- **저장 가능 데이터**: JPEG 이미지, 바이트 값, HTTP 응답값, 바이너리 데이터 등 모든 종류의 문자열
- **안전성**: 이진 데이터를 포함한 모든 문자열이 **binary-safe**하게 저장됨

### Binary-Safe의 의미

일반 프로그래밍 언어는 null 바이트(`\0`)를 만나면 문자열의 끝으로 간주합니다.
```
C언어 문자열: "Hello\0World" → "Hello"만 저장 (그 뒤는 무시)
```

**Redis는 다릅니다**: null 바이트를 특별히 취급하지 않고 단순히 **바이트의 배열로 처리**합니다.
```
Redis String: "Hello\0World" → "Hello\0World" 전체가 저장됨
```
따라서 바이트 중간에 null이 포함된 이미지, PDF, 바이너리 데이터도 손상 없이 저장 가능합니다.

### 주요 커맨드 및 옵션

**기본 저장 옵션**

| 옵션   | 동작                         | 사용 시점       |
| ---- | -------------------------- | ----------- |
| `NX` | 키가 **없을 경우만** 저장 (기존 키 보존) | 중복 방지 필요할 때 |
| `XX` | 키가 **있을 경우만** 덮어쓰기         | 업데이트만 수행    |

**숫자 조작 (원자적 연산)**
```
INCR key              // 1씩 증가
INCRBY key increment  // increment만큼 증가
DECR key              // 1씩 감소
DECRBY key decrement  // decrement만큼 감소
```

**원자적(Atomic)의 의미**: 같은 키에 접근하는 여러 클라이언트가 경쟁 상태(Race Condition)를 발생시킬 일이 없습니다.

- 커맨드 실행 타이밍이나 순서에 상관없이 일관된 결과 보장
- 커맨드가 무시되거나 중복 처리되지 않음

**멀티 커맨드 (대규모 시스템 성능 최적화)**
```
MSET key1 value1 key2 value2 ... keyN valueN
MGET key1 key2 ... keyN
```
여러 key-value를 한 번에 처리하므로 대규모 시스템에서 속도 향상에 도움됩니다.

### 실무 활용 예상
- 세션 저장, 캐시 데이터
- 조회 카운트, 방문자 수 (원자적 증감)
- 이미지, PDF 등 바이너리 파일 저장
- 마이크로서비스 간 빠른 데이터 교환

---

## 2. List - 순서가 있는 데이터

### 기본 개요

**순서를 가지는 문자열의 목록**입니다. 양쪽 끝에서만 효율적으로 추가/제거 가능합니다.

- **최대 아이템 개수**: 약 42억 개
- **특징**: 인덱스 접근 가능, 중복 값 허용
- **활용**: Stack(LIFO), Queue(FIFO), 로그 저장 등

### 시간 복잡도 (성능의 핵심)

| 작업                      | 시간복잡도    | 설명          |
| ----------------------- | -------- | ----------- |
| 양쪽 끝(Head/Tail)에서 추가/제거 | **O(1)** | 매우 빠름       |
| **중간 데이터 접근**           | **O(N)** | ⚠️ 성능 저하 위험 |
| 범위 조회                   | O(N)     | 범위 크기만큼 소요  |

**중요**: 중간 접근이 빈번하다면 List가 아닌 **Hash나 Sorted Set**을 고려

### 핵심 커맨드

#### 추가/제거

```
LPUSH key element [element...]     // 왼쪽(Head)에서 추가
RPUSH key element [element...]     // 오른쪽(Tail)에서 추가
LPOP key [count]                   // 왼쪽에서 추출 (값 반환 + 삭제)
RPOP key [count]                   // 오른쪽에서 추출
```

#### 조회

```
LRANGE key start stop              // 범위 조회 (양쪽 끝에서 -1, -2로 역인덱싱 가능)
LINDEX key index                   // 특정 인덱스 조회 (O(N) 주의)
```

#### 수정/정리

```
LSET key index element             // 인덱스 위치의 값 변경
LINSERT key BEFORE|AFTER pivot element   // 특정 값의 앞/뒤에 삽입
LTRIM key start stop               // 범위 외 데이터 삭제 (범위 내만 보존)
```

### 주요 사용 패턴

#### 1️⃣ Stack (LIFO)

```
LPUSH stack_key value          // 데이터 추가
LPOP stack_key                 // 데이터 제거 및 반환 (마지막 추가된 것부터)
```

#### 2️⃣ Queue (FIFO)

```
RPUSH queue_key value          // 오른쪽에 추가
LPOP queue_key                 // 왼쪽에서 추출
```

#### 3️⃣ 고정된 큐 (Fixed-Size Queue) - 로그 저장에 최적

```
LPUSH log_key new_log_entry
LTRIM log_key 0 999            // 최신 1000개만 유지 (나머지 자동 삭제)
```

**왜 효율적인가?**

- **O(1) 복잡도**: 추가(1개) + 삭제(끝에 1개) = 상수 시간
- **용량 관리**: 로그 데이터를 계속 쌓으면 메모리 부족 → LTRIM으로 해결
- **실무 활용**: 최근 로그, 방문 기록, 활동 피드 등

### 실무 활용 예상

|상황|커맨드 조합|
|---|---|
|최근 로그 100개 유지|LPUSH + LTRIM|
|작업 큐 처리|RPUSH + LPOP|
|페이지 뷰 히스토리|LPUSH + LRANGE|
|실시간 알림|RPUSH (추가) / LPOP (처리)|

---

## 3. Hash - 필드-값 쌍 저장

### 기본 개요

**하나의 Hash 내에서 여러 필드-값 쌍을 저장**합니다. 관계형 데이터베이스의 **테이블 한 행(Row)**처럼 생각하면 됩니다.

- **구조**: `Hash Key` → 여러 개의 `(Field, Value)` 쌍
- **특징**: 필드는 Hash 내에서 유일, 필드와 값 모두 문자열 저장
- **유연성**: 동적으로 필드 추가/제거 가능 (스키마 변경 불필요)
- **활용**: 사용자 프로필, 제품 정보, 설정값 등

### 데이터 구조 예시

```
HSET user:123 name "John" age "30" email "john@example.com"

Redis 메모리에 저장되는 구조:
{
  "user:123": {
    "name": "John",
    "age": "30",
    "email": "john@example.com"
  }
}
```

### 시간 복잡도

|작업|시간복잡도|설명|
|---|---|---|
|HSET / HGET|**O(1)**|매우 빠름|
|HGETALL|**O(N)**|필드 개수만큼 소요|
|HMGET|**O(N)**|조회 필드 개수만큼 소요|

### 핵심 커맨드

#### 저장 및 조회

```
HSET key field value [field value...]    // 1개 이상의 필드-값 저장
HGET key field                           // 특정 필드의 값 조회
HMGET key field [field...]               // 여러 필드의 값 조회
HGETALL key                              // 모든 필드-값 쌍 조회
```

#### 필드 관련

```
HEXISTS key field                        // 필드 존재 여부 확인
HDEL key field [field...]                // 필드 삭제
HKEYS key                                // 모든 필드명 조회
HVALS key                                // 모든 값 조회
HLEN key                                 // 필드 개수 조회
```

#### 숫자 연산

```
HINCRBY key field increment              // 필드값을 숫자로 증가
HINCRBYFLOAT key field increment         // 필드값을 실수로 증가
```

### Hash vs String 비교

|측면|String|Hash|
|---|---|---|
|데이터 구조|단순 텍스트|필드-값 쌍|
|스키마|고정|동적|
|메모리 효율|개별 저장|더 효율적|
|일부 업데이트|전체 교체|필드만 수정|

**String으로 같은 정보 저장하면?**

```
SET user:123:name "John"
SET user:123:age "30"
SET user:123:email "john@example.com"
// 3개의 독립된 키 필요
```

**Hash로 저장하면?**

```
HSET user:123 name "John" age "30" email "john@example.com"
// 1개의 키로 관리
```

---

## 4. Set - 중복 없는 집합

### 기본 개요

**정렬되지 않은 유일한 문자열의 모음**입니다. 순서가 없고, 중복된 원소를 허용하지 않습니다.

- **특징**: 순서 없음, 중복 불가능, 유일성 보장
- **핵심 기능**: 집합 연산 (합집합, 교집합, 차집합)
- **활용**: 태그, 팔로우 관계, 추천 시스템, 유일값 추적 등

### 시간 복잡도

|작업|시간복잡도|설명|
|---|---|---|
|SADD / SREM|**O(1)**|매우 빠름|
|SMEMBERS|**O(N)**|원소 개수만큼 소요|
|SINTER / SUNION / SDIFF|**O(N+M)**|집합 크기에 따라 소요|
|SPOP|**O(1)**|빠른 랜덤 추출|

### 핵심 커맨드

#### 저장 및 조회

```
SADD key member [member...]          // 1개 이상의 원소 저장 (중복 자동 제거)
SMEMBERS key                         // 모든 원소 조회 (순서 무관)
SCARD key                            // 원소 개수 조회
SISMEMBER key member                 // 특정 원소 존재 여부 확인
```

#### 제거

```
SREM key member [member...]          // 특정 원소 삭제
SPOP key [count]                     // 랜덤 원소 조회 + 삭제
```

#### 집합 연산 (핵심!)

```
SUNION key [key...]                  // 합집합: 모든 원소 모음
SINTER key [key...]                  // 교집합: 공통 원소만
SDIFF key [key...]                   // 차집합: 첫 번째 Set에서만 있는 원소
```

**집합 연산 저장하기** (결과를 새로운 Set으로 저장)

```
SUNIONSTORE dest_key key1 key2       // 합집합 결과 저장
SINTERSTORE dest_key key1 key2       // 교집합 결과 저장
SDIFFSTORE dest_key key1 key2        // 차집합 결과 저장
```

### 실제 사용 예시

#### 1️⃣ 공통 관심사 찾기 (교집합)

```
SADD hobby:john "reading" "gaming" "cooking"
SADD hobby:jane "gaming" "swimming" "cooking"

SINTER hobby:john hobby:jane
// 결과: {"gaming", "cooking"}  → John과 Jane의 공통 취미
```

**실무 활용**: 추천 시스템 (공통 관심사가 있는 사용자들에게 서로 추천)

#### 2️⃣ 좋아요 유일성 보장 (중복 방지)

```
SADD post:123:likes user:john
SADD post:123:likes user:jane
SADD post:123:likes user:john    // 이미 있으면 추가 안됨

SCARD post:123:likes             // 좋아요 개수: 2
```

**vs List로 하면?** LPUSH로 계속 추가되어 같은 사용자가 여러 번 나타날 수 있음.

### 실무 활용 예상

|상황|커맨드|
|---|---|
|게시물 좋아요|SADD post:123:likes user:john|
|팔로우 관계|SADD user:john:following user:alice|
|공통 관심사 추천|SINTER user:john:interests user:alice:interests|
|온라인 사용자 추적|SADD online:users user:john|
|이메일 구독자|SADD subscribers:newsletter user:john user:alice|

---

## 5. Sorted Set - 정렬된 집합

### 기본 개요

**스코어(Score) 값에 따라 정렬되는 고유 문자열의 집합**입니다. Set의 유일성을 보지만 순서가 있고, List처럼 인덱스 접근이 가능합니다.

- **특징**: 중복 불가능, 스코어로 정렬, 같은 스코어면 사전 순 정렬
- **정렬**: 스코어 오름차순 → 스코어 같으면 문자열 사전 순
- **활용**: 랭킹, 점수 관리, 타임시리즈 데이터, 우선순위 큐 등
- **성능**: 인덱스 접근 시 **List O(N) vs Sorted Set O(log N)** → 매우 효율적

### 시간 복잡도

|작업|시간복잡도|설명|
|---|---|---|
|ZADD|**O(log N)**|정렬 유지하며 삽입|
|ZRANGE (인덱스)|**O(log N + K)**|K = 조회 범위 크기|
|**ZRANGE (스코어)**|**O(log N + K)**|이진 탐색으로 빠름|
|ZCARD|**O(1)**|빠름|

**vs List**: List의 인덱스 접근은 O(N) → Sorted Set이 훨씬 효율적!

### 핵심 커맨드

#### 저장

```
ZADD key score member [score member...]      // 아이템 추가/스코어 업데이트
```

**ZADD 옵션들:**

|옵션|동작|사용 시점|
|---|---|---|
|`XX`|기존 아이템의 스코어만 업데이트 (신규 삽입 안함)|점수 갱신만 필요|
|`NX`|새 아이템만 삽입 (기존 아이템 스코어 유지)|중복 방지하며 추가|
|`LT`|새 스코어 < 기존 스코어일 때만 업데이트|최소값만 유지|
|`GT`|새 스코어 > 기존 스코어일 때만 업데이트|최대값만 유지|

#### 조회: ZRANGE (가장 중요한 커맨드)

**1️⃣ 인덱스로 조회 (기본 동작)**

```
ZRANGE key start stop [WITHSCORES] [REV]
```

- `start/stop`: 인덱스 범위 (0부터 시작, -1은 마지막)
- `WITHSCORES`: 스코어도 함께 출력
- `REV`: 역순 조회 (스코어 높은 순)

**2️⃣ 스코어로 조회 (BYSCORE)**

```
ZRANGE key min max BYSCORE [WITHSCORES]
```

스코어의 최소값과 최대값을 지정하여 범위 조회합니다.

**포함/제외 기호:**

|기호|의미|예시|
|---|---|---|
|`[`|**포함**|`[100` = 100 포함|
|`(`|**제외**|`(100` = 100 제외|
|`-inf`|음의 무한대|최소값 이상|
|`+inf`|양의 무한대|최대값 이상|

**예시:**

```
ZADD scores 50 a 100 b 150 c 200 d 250 e

ZRANGE scores 100 200 BYSCORE           // [b, c, d] (100 ≤ score ≤ 200)
ZRANGE scores (100 200 BYSCORE          // [c, d] (100 < score ≤ 200)
ZRANGE scores 100 (200 BYSCORE          // [b, c] (100 ≤ score < 200)
ZRANGE scores (100 (200 BYSCORE         // [c] (100 < score < 200)
ZRANGE scores 200 +inf BYSCORE          // [d, e] (score ≥ 200)
ZRANGE scores -inf 100 BYSCORE          // [a, b] (score ≤ 100)
```

### 실무 활용 예상

|상황|커맨드|
|---|---|
|게임 랭킹 (높은 점수순)|ZADD ranking 100 user:john; ZRANGE ranking 0 -1 REV|
|특정 점수 범위 사용자|ZRANGE ranking 1000 5000 BYSCORE|
|로그 저장 (타임스탬프 스코어)|ZADD logs `date +%s` "event data"|
|우선순위 큐|ZADD queue 1 task:high; ZPOPMIN queue|

---

## 6. Bitmap - 비트 단위 연산

### 기본 개요

**String 자료구조에 비트 연산 기능을 더한 특화된 형태**입니다. 독자적인 자료구조가 아니라, String의 진화된 활용법입니다.

- **본질**: String 저장 + 비트 레벨 연산
- **저장 공간**: String의 512MB 제한 → 최대 **2^32개의 비트** 저장 가능
- **핵심 장점**: **공간 효율성 극대화**
- **활용**: 활성 사용자 추적, 방문 기록, 권한 관리, 온라인 상태 등

### 공간 효율성 비교

#### 시나리오: 40억 사용자의 일일 활성 여부 저장 (Y/N)

**방법 1: String으로 저장 (비효율)**

```
SET active:2025-01-15:user:1 "true"
SET active:2025-01-15:user:2 "false"
SET active:2025-01-15:user:3 "true"
... (40억 번)

각 데이터: 약 30-50바이트
필요 메모리: 40억 × 40바이트 = 약 160GB 이상
```

**방법 2: Bitmap 사용 (효율적) ✅**

```
SETBIT active:2025-01-15 1 1
SETBIT active:2025-01-15 2 0
SETBIT active:2025-01-15 3 1
... (40억 번)

계산: 40억 비트 ÷ 8 = 500MB
필요 메모리: 약 512MB

차이: 약 320배 메모리 절감!
```

### 핵심 커맨드

#### 개별 비트 조작

```
SETBIT key offset value           // 특정 offset의 비트를 0 또는 1로 설정
GETBIT key offset                 // 특정 offset의 비트값 조회
BITCOUNT key [start end]          // 비트값이 1인 개수 세기
```

#### 집합 연산 (비트 연산)

```
BITOP AND dest key1 key2 ...      // AND 연산 결과를 dest에 저장
BITOP OR dest key1 key2 ...       // OR 연산
BITOP XOR dest key1 key2 ...      // XOR 연산
BITOP NOT dest key                // NOT 연산
```

### 실무 활용 패턴

#### 1️⃣ 일일 활성 사용자 추적 (DAU)

```
// 2025-01-15에 사용자 1234가 로그인
SETBIT dau:2025-01-15 1234 1

// 해당 날짜 활성 사용자 수
BITCOUNT dau:2025-01-15
→ 결과: 오늘 로그인한 총 사용자 수

// 7일간 활성한 사용자 중복 제거 (합집합)
BITOP OR dau:week dau:2025-01-09 dau:2025-01-10 ... dau:2025-01-15
BITCOUNT dau:week
→ 결과: 지난주에 최소 1번 이상 로그인한 사용자 수

// 7일 모두 활성한 사용자 (교집합)
BITOP AND dau:all-days dau:2025-01-09 dau:2025-01-10 ... dau:2025-01-15
BITCOUNT dau:all-days
→ 결과: 지난주 매일 로그인한 사용자 수 (VIP 사용자 추출)
```

---

## 7. HyperLogLog - 효율적인 카디널리티 추정

### 기본 개요

**중복되지 않는 고유한 원소의 개수(카디널리티)를 추정하는 자료구조**입니다. Set과 유사하지만 **데이터 자체를 저장하지 않고 추정값만 저장**하는 획기적으로 효율적인 구조입니다.

- **본질**: 입력 데이터 처리 후 패턴만 저장 (실제 데이터 미저장)
- **메모리**: 데이터 개수 관계없이 **항상 12KB 이하**
- **저장 가능**: 최대 2^64개 아이템 카디널리티 추정 가능
- **정확도**: 약 99% (오차율 약 0.81%)
- **활용**: 일일 방문자 수, 웹사이트 UU(유니크 사용자), 실시간 통계 등

### Set vs HyperLogLog 비교

|항목|Set|HyperLogLog|
|---|---|---|
|**저장 데이터**|모든 원소 보존|데이터 보존 X|
|**메모리**|데이터량에 따라 증가|항상 12KB|
|**메모리 예시**|1억 개 = 약 100MB|1억 개 = 12KB|
|**정확도**|100% 정확|약 99% (오차 최대 1%)|
|**개수 조회**|SCARD|PFCOUNT|
|**데이터 조회**|SMEMBERS 가능|불가능|
|**용도**|유일한 데이터 관리|개수만 추정|

### 메모리 효율성 비교

#### 시나리오: 구글 같은 서비스의 일일 방문자 수

**방법 1: Set 사용 (비효율)**

```
일일 방문자: 약 50억 명

SET google:dau:2025-01-15 "session:1"
SET google:dau:2025-01-15 "session:2"
...
SET google:dau:2025-01-15 "session:5000000000"

필요 메모리: 50억 × 약 100바이트 = 약 500GB
```

**방법 2: HyperLogLog 사용 (효율적) ✅**

```
PFADD google:dau:2025-01-15 "session:1"
PFADD google:dau:2025-01-15 "session:2"
...
PFADD google:dau:2025-01-15 "session:5000000000"

필요 메모리: 약 12KB
결과: 약 50억 명 (±1% 오차)

차이: 약 40,000배 메모리 절감!
```

### 핵심 커맨드

#### 데이터 추가

```
PFADD key element [element...]     // 원소 추가 (중복 자동 제거)
```

#### 카디널리티 조회

```
PFCOUNT key [key...]               // 고유 원소 개수 추정
```

**예시 1: 단일 날짜 방문자 수**

```
PFCOUNT dau:2025-01-15
→ 결과: 약 3 (정확값: 3)
```

**예시 2: 여러 날짜 합친 방문자 (합집합 추정)**

```
PFCOUNT dau:2025-01-13 dau:2025-01-14 dau:2025-01-15
→ 결과: 약 8 (3일간 중복 제거한 총 유니크 방문자)
```

#### 여러 HyperLogLog 합치기

```
PFMERGE dest key [key...]          // 여러 HyperLogLog를 합쳐서 새 key 생성
```

**예시: 월간 UU(유니크 사용자) 계산**

```
PFMERGE mau:2025-01 \
  dau:2025-01-01 dau:2025-01-02 dau:2025-01-03 ... dau:2025-01-31

PFCOUNT mau:2025-01
→ 결과: 1월 총 유니크 방문자 수 (중복 제거)
```

### 언제 뭘 쓰나?

#### Set 사용 ✅

```
✅ 정확한 명단이 필요할 때
✅ "정확히 누가 왔나?" 알고 싶을 때
✅ 1% 오차도 허용 못 할 때

예: 친구 목록, 팔로우 리스트, 금융 거래 기록
```

#### HyperLogLog 사용 ✅

```
✅ "대략 몇 명이 왔는가?"만 알면 될 때
✅ 메모리가 중요할 때 (대규모 데이터)
✅ 정확도 1% 오차는 괜찮을 때

예: 일일 방문자 수, 웹사이트 UU, 앱 다운로드 수
```

---

## 8. Geospatial - 위치 데이터 관리

### 기본 개요

**경도(Longitude)와 위도(Latitude) 데이터 쌍으로 지리적 위치 정보를 저장하고 조회하는 자료구조**입니다.

- **저장 형식**: 경도, 위도, 멤버명 (예: 127.0276, 37.4979, "서울시청")
- **내부 구조**: Sorted Set을 기반으로 구현 (스코어는 지오해시)
- **유일성**: 하나의 키 내에서 멤버는 중복 저장 불가능
- **활용**: 근처 매장 검색, 배달 위치 추적, 위치 기반 서비스 등

### 좌표계 이해하기

#### 경도(Longitude) vs 위도(Latitude)

```
위도(Latitude)
↑ 북쪽 90도
│
│  37.4979 (서울)
│
├─────────────────→ 경도(Longitude)
│
│  0도 (그리니치 자오선)
↓
남쪽 -90도


경도: -180 ~ 180 (동쪽 양수, 서쪽 음수)
위도: -90 ~ 90 (북쪽 양수, 남쪽 음수)
```

### 핵심 커맨드

#### 1. GEOADD: 위치 데이터 추가

```
GEOADD key 경도 위도 member [경도 위도 member ...]
```

**예시: 카페 위치 저장**

```
# 강남역 카페
GEOADD cafe 127.0276 37.4979 "gangnam_cafe"

# 여러 카페 한번에 추가
GEOADD cafe \
  127.0276 37.4979 "gangnam_cafe" \
  126.9917 37.5642 "hongdae_cafe" \
  126.9882 37.5665 "myeongdong_cafe"

반환: 3 (3개 추가됨)
```

#### 2. GEOPOS: 저장된 위치 조회

```
GEOPOS key member [member ...]
```

**예시**

```
GEOPOS cafe "gangnam_cafe"
→ 결과: [127.02759, 37.49790] (약간의 부동소수점 오차 가능)
```

#### 3. GEODIST: 두 위치 사이의 거리 계산

```
GEODIST key member1 member2 [m|km|ft|mi]
```

**거리 단위**:

- `m`: 미터 (기본값)
- `km`: 킬로미터
- `ft`: 피트
- `mi`: 마일

**예시**

```
# 강남 카페와 명동 카페 사이의 거리 (단위: 킬로미터)
GEODIST cafe "gangnam_cafe" "myeongdong_cafe" km
→ 결과: 8.3741 (약 8.37km)
```

#### 4. GEOSEARCH: 범위 내 위치 검색 (가장 강력!)

```
GEOSEARCH key FROMMEMBER member BYRADIUS radius m|km|ft|mi [WITHCOORD] [WITHDIST] [COUNT count]
```

**옵션 설명**:

- `FROMMEMBER`: 기준이 되는 멤버
- `BYRADIUS`: 반경 거리 기준 (원형)
- `WITHCOORD`: 결과에 좌표 포함
- `WITHDIST`: 결과에 거리 포함
- `COUNT`: 반환할 결과 개수 제한

**예시: 반경 기준 검색**

```
# 강남 카페로부터 9km 이내 카페 (거리 정보 포함)
GEOSEARCH cafe FROMMEMBER "gangnam_cafe" BYRADIUS 9 km WITHDIST

결과:
1) 1) "gangnam_cafe"
   2) "0.0000"
3) 1) "hongdae_cafe"
   4) "8.0151"
5) 1) "myeongdong_cafe"
   6) "8.3741"
```

### 실제 사용 예제

#### 배달 앱의 근처 음식점 검색

```
# 음식점 위치 저장
GEOADD restaurant \
  127.0276 37.4979 "강남치킨" \
  126.9917 37.5642 "홍대피자" \
  126.9882 37.5665 "명동버거"

# 사용자가 강남치킨에서 9km 이내의 음식점 검색
GEOSEARCH restaurant FROMMEMBER "강남치킨" BYRADIUS 9 km WITHDIST

결과:
1) 1) "강남치킨"
   2) "0.0000"
3) 1) "명동버거"
   4) "8.3741"
5) 1) "홍대피자"
   6) "8.0151"
```

---

## 9. Stream - 메시지 브로커

### 기본 개요

**메시지 브로커(Kafka 같은)처럼 동작하는 자료구조로, 실시간 이벤트와 로그성 데이터를 저장하고 처리**합니다. Append-only 방식으로 데이터를 계속 추가하며, 소비자 그룹 개념으로 분산 처리를 지원합니다.

- **특징**: 메시지 브로커, 이벤트 로깅, 분산 처리
- **저장 방식**: Append-only (데이터는 추가만 됨, 삭제 불가)
- **메시지 ID**: 타임스탬프 기반 (자동 생성 가능)
- **소비자 그룹**: 여러 워커가 메시지를 분담 처리
- **활용**: 실시간 알림, 로그 수집, 이벤트 처리, 작업 큐 등

### Stream vs 다른 자료구조 비교

|항목|List|Sorted Set|**Stream**|
|---|---|---|---|
|**용도**|순서 있는 데이터|정렬된 데이터|메시지 브로커|
|**메시지 ID**|자동 증가 인덱스|스코어|타임스탬프 기반|
|**소비자 그룹**|❌ 없음|❌ 없음|✅ **있음**|
|**이력 추적**|❌ 없음|❌ 없음|✅ **처리 이력 저장**|
|**미확인 메시지**|❌ 없음|❌ 없음|✅ **추적 가능**|
|**분산 처리**|❌ 어려움|❌ 어려움|✅ **지원**|

### 핵심 커맨드

#### 1. XADD: 메시지 추가

```
XADD key [ID] field value [field value ...]
```

**예시**

```
# 자동 ID 생성으로 메시지 추가
XADD orders * order_id "123" user_id "user:100" amount "50000"
→ 반환: "1705315200000-0" (자동 생성된 ID)
```

#### 2. XLEN: 스트림 크기 조회

```
XLEN key
```

#### 3. XRANGE: 범위 조회

```
XRANGE key start end [COUNT count]
```

**예시**

```
# 첫 번째 메시지부터 마지막까지 조회
XRANGE orders - +

# 최근 2개만 조회
XRANGE orders - + COUNT 2
```

#### 4. XREAD: 메시지 읽기 (기본)

```
XREAD [COUNT count] [BLOCK milliseconds] STREAMS key id
```

#### 5. XGROUP CREATE: 소비자 그룹 생성

```
XGROUP CREATE key group id [MKSTREAM]
```

**예시**

```
# 소비자 그룹 생성 (ID $: 새 메시지부터 처리)
XGROUP CREATE orders payment_group $

# 소비자 그룹 생성 (ID 0: 처음부터 처리)
XGROUP CREATE orders notification_group 0
```

#### 6. XREADGROUP: 그룹으로 메시지 읽기

```
XREADGROUP GROUP group consumer [COUNT count] [BLOCK ms] STREAMS key id
```

**예시**

```
# payment_group 그룹의 worker1이 메시지 읽기
XREADGROUP GROUP payment_group worker1 STREAMS orders >

# worker2도 같은 그룹에서 읽기 (다른 메시지를 받음)
XREADGROUP GROUP payment_group worker2 STREAMS orders >
```

#### 7. XACK: 메시지 처리 확인

```
XACK key group id [id ...]
```

**예시**

```
# 메시지 처리 완료 확인
XACK orders payment_group "1705315200000-0"
→ 반환: 1 (1개 확인됨)
```

#### 8. XPENDING: 미확인 메시지 조회

```
XPENDING key group [start end count] [consumer]
```

**설명**: 아직 처리되지 않은(XACK 미실행) 메시지 목록을 조회합니다.

### 실제 사용 예제: 분산 작업 처리

**시나리오**: 주문 처리를 여러 워커가 분담 처리

```
# 1. 소비자 그룹 생성 (처음부터 모든 메시지 처리)
XGROUP CREATE orders payment_workers 0

# 2. 주문 데이터 추가
XADD orders * order_id "001" status "pending" amount "50000"
XADD orders * order_id "002" status "pending" amount "75000"
XADD orders * order_id "003" status "pending" amount "30000"

# 3. Worker1이 메시지 읽기
XREADGROUP GROUP payment_workers worker1 COUNT 2 STREAMS orders >
결과: 주문 001, 002를 받음

# 4. Worker2가 메시지 읽기
XREADGROUP GROUP payment_workers worker2 COUNT 1 STREAMS orders >
결과: 주문 003을 받음
(001, 002는 worker1이 처리 중이므로 건너뜀)

# 5. Worker1이 주문 001 처리 완료
XACK orders payment_workers "1705315200000-0"

# 6. 미처리 메시지 확인
XPENDING orders payment_workers
→ 결과: Worker1의 주문002, Worker2의 주문003 표시
```

---

## 10. 키 관리 - 효율적인 키 운영

### 기본 개요

Redis의 키 관리는 **효율적인 데이터 조회, 삭제, 만료 설정**을 통해 메모리를 효율적으로 관리하는 것입니다. 모든 자료구조는 공통된 키 관리 규칙을 따릅니다.

- **특징**: 자동 생성/삭제, 패턴 매칭, TTL(Time To Live) 설정
- **중요**: 키 관리 전략이 Redis 성능에 큰 영향을 미침
- **활용**: 메모리 최적화, 자동 정리, 데이터 만료

### 키의 자동 생성과 삭제 규칙

#### 기본 동작 원리

```
규칙 1: 키가 없으면 자동 생성
LPUSH mylist "item1"
↓
"mylist" 키가 없음
↓
자동으로 List 자료구조 생성
↓
"item1" 추가
↓
OK 반환

규칙 2: 모든 아이템 삭제 시 키도 자동 삭제
LPOP mylist (마지막 아이템 제거)
↓
"mylist" 키 자동 삭제
↓
KEYS * 조회하면 "mylist" 없음

규칙 3: 읽기 커맨드는 키 없으면 빈 값 반환
LRANGE nonexistent 0 -1
↓
(empty array) 반환 (에러 아님, 정상)

⚠️ 예외: Stream은 마지막 아이템 삭제 후에도 키 유지
```

### 키 조회 커맨드

#### 1. EXISTS: 키 존재 여부 확인

```
EXISTS key [key...]
```

**예시**
```
EXISTS user:100 user:200 product:1
→ 반환: 2 (2개 키 존재)
```

#### 2. KEYS: 패턴 매칭으로 모든 키 조회

```
KEYS pattern
```

**Glob 패턴 문법**

```
*       : 모든 문자 (0개 이상)
?       : 정확히 1개 문자
[abc]   : a, b, c 중 하나
[a-z]   : a~z 범위
[^ae]   : a, e 제외
```

**⚠️ 주의사항**

```
KEYS는 위험한 커맨드!

문제:
- 모든 키를 조회하는 동안 Redis 블로킹
- 다른 모든 작업 대기
- 키가 많으면 fail-over 발생 가능

✅ KEYS 사용 시기:
- 개발/테스트 환경만
- 키가 매우 적을 때만
```

#### 3. SCAN: 안전한 키 조회 (권장)

```
SCAN cursor [MATCH pattern] [COUNT count] [TYPE type]
```

**설명**: 커서 기반으로 일부 키만 조회하여 KEYS보다 안전합니다.

**예시**

```
# 첫 번째 스캔
SCAN 0 MATCH user:* COUNT 10
→ 반환: ["21", ["user:100", "user:200", ...]]
        (커서 21, 키 목록)

# 두 번째 스캔 (커서 21 사용)
SCAN 21 MATCH user:* COUNT 10
→ 반환: ["27", ["user:300", "user:400", ...]]

# 세 번째 스캔
SCAN 27 MATCH user:* COUNT 10
→ 반환: ["0", [...]]
        (커서 0 = 모든 키 조회 완료)
```

**SCAN의 장점**

```
KEYS vs SCAN 비교:

KEYS user:*
├─ Redis 블로킹 (동기)
├─ 모든 키 조회 (큼)
└─ 위험! ❌

SCAN 0 MATCH user:*
├─ 점진적 조회 (비동기)
├─ 일부 키만 반환
├─ 다른 작업 처리 가능 ✅
└─ 안전! 권장됨
```

### 키 삭제 커맨드

#### 1. DEL: 동기 삭제

```
DEL key [key...]
```

**특징**: 키와 모든 아이템을 **동기적으로** 삭제합니다.

**문제점**

```
❌ 큰 데이터 삭제 시 문제:

SET mylist big_data (100MB)
DEL mylist
→ 메모리 해제하는 동안 Redis 블로킹
→ 다른 모든 작업 대기
→ 응답 지연
```

#### 2. UNLINK: 비동기 삭제 (권장)

```
UNLINK key [key...]
```

**특징**: 키를 **백그라운드에서** 비동기 삭제합니다.

**동작 원리**

```
UNLINK mylist
↓
1단계: 키와 데이터의 연결 끊기 (즉시)
→ Redis 응답 가능 ✅
↓
2단계: 메모리 해제 (백그라운드, 다른 스레드)
→ Redis 블로킹 없음
```

**예시**

```
# 큰 데이터 삭제 (안전)
UNLINK big_list big_set big_hash
→ 즉시 반환, 백그라운드에서 정리

# DEL vs UNLINK
DEL user:huge_data      → 10초 블로킹
UNLINK user:huge_data   → 즉시 반환
```

### 키 만료 시간 (TTL) 관리

#### 1. EXPIRE: 초 단위 TTL 설정

```
EXPIRE key seconds [NX|XX|GT|LT]
```

**설명**: 키가 지정된 시간 후에 자동으로 삭제됩니다.

**옵션**

```
NX : 키에 TTL이 없을 때만 설정
XX : 키에 TTL이 있을 때만 설정
GT : 새 TTL이 기존 TTL보다 클 때만 설정
LT : 새 TTL이 기존 TTL보다 작을 때만 설정
```

**예시**

```
# 기본 사용
SET session:abc "user123"
EXPIRE session:abc 3600
→ 1시간 후 자동 삭제 ✅

# 옵션 활용
EXPIRE session:abc 7200 NX
→ TTL 없을 때만 2시간 설정

EXPIRE session:abc 1800 XX
→ TTL 있을 때만 30분으로 변경
```

#### 2. TTL / PTTL: 남은 시간 확인

```
TTL key              (초 단위)
PTTL key             (밀리초 단위)
```

**반환값**

```
양수        : 남은 시간
-1          : TTL 없음 (영구 저장)
-2          : 키 없음
```

**예시**

```
EXPIRE mykey 100
TTL mykey
→ 99 (약 99초 남음)

PTTL mykey
→ 99000 (약 99초 = 99,000ms)

# TTL 없는 키
TTL permanent_key
→ -1

# 없는 키
TTL nonexistent
→ -2
```

#### 3. PERSIST: TTL 제거

```
PERSIST key
```

**설명**: 키의 TTL을 제거하여 영구 저장으로 변경합니다.

**예시**

```
EXPIRE mykey 3600
TTL mykey
→ 3600

PERSIST mykey
TTL mykey
→ -1 (TTL 없음, 영구 저장)
```

### TTL 실제 사용 패턴

#### 패턴 1: 세션 캐시 (자동 만료)

```
사용자 로그인:
SET session:abc123 "user:100" EX 3600
→ 1시간 후 자동 삭제 ✅

장점:
- 수동으로 삭제 안 해도 됨
- 메모리 자동 관리
- 보안 강화 (오래된 세션 자동 제거)
```

#### 패턴 2: 캐시 데이터 (짧은 TTL)

```
캐시 저장:
SET cache:product:100 "$50" EX 300
→ 5분 후 자동 새로고침 필요

캐시 갱신:
GET cache:product:100
→ nil (만료됨)
→ DB에서 재조회 후 다시 캐시
```

#### 패턴 3: 중요 데이터 (TTL 없음)

```
사용자 정보:
SET user:100 "{...}"
→ TTL 없음 (영구 저장) ✅

주문 데이터:
SET order:123 "{...}"
→ TTL 없음 (영구 저장) ✅

이유: 데이터 손실 방지
```

### 시간 복잡도

|커맨드|복잡도|설명|
|---|---|---|
|EXISTS|O(1)|키 존재 확인|
|KEYS|O(N)|⚠️ 위험 (N = 전체 키)|
|SCAN|O(1)|커서당 일부 키만|
|TYPE|O(1)|타입 확인|
|DEL|O(N)|N = 삭제 아이템 수|
|UNLINK|O(1)|연결 끊기만 (정리는 BG)|
|EXPIRE|O(1)|TTL 설정|
|TTL|O(1)|남은 시간 조회|

### 핵심 정리

|작업|커맨드|안전도|
|---|---|---|
|**키 확인**|EXISTS|✅ 안전|
|**키 조회**|SCAN|✅ 권장|
|**키 조회**|KEYS|❌ 위험|
|**키 삭제**|DEL|⚠️ 조심|
|**키 삭제**|UNLINK|✅ 권장|
|**TTL 설정**|EXPIRE|✅ 안전|
|**TTL 확인**|TTL|✅ 안전|

---

## 마무리

Redis는 다양한 자료구조를 제공하여 다양한 비즈니스 요구사항을 효율적으로 처리할 수 있습니다.

### Redis 자료구조 선택 가이드

- **String**: 단순 데이터, 캐시, 카운터
- **List**: 순서 중요, 큐/스택, 로그
- **Hash**: 객체 저장, 사용자 정보
- **Set**: 중복 제거, 집합 연산
- **Sorted Set**: 랭킹, 정렬된 데이터
- **Bitmap**: 대량 이진 데이터, 활성 사용자 추적
- **HyperLogLog**: 대규모 카디널리티 추정
- **Geospatial**: 위치 기반 서비스
- **Stream**: 이벤트 처리, 메시지 큐

### Redis 키 관리 3대 원칙

```
1️⃣ 조회: SCAN 사용 (KEYS 금지)
   → 안전하고 효율적

2️⃣ 삭제: UNLINK 사용 (DEL 지양)
   → 비동기 처리로 블로킹 방지

3️⃣ 만료: EXPIRE로 자동 정리
   → 메모리 자동 관리
```

---

## 추천 태그

Redis, 레디스, 자료구조, 데이터베이스, NoSQL, 캐시, 인메모리데이터베이스, String, List, Hash, Set, SortedSet, Bitmap, HyperLogLog, Geospatial, Stream, 키관리, TTL, 메모리최적화, 성능최적화
